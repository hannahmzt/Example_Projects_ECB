{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6adf131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3c71ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.11.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
      "\u001b[K     |████████████████████████████████| 400 kB 29.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2021.10.8\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 35.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/hannahmeyerzutittingdorf/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.26.4)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: sortedcontainers in /Users/hannahmeyerzutittingdorf/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /Users/hannahmeyerzutittingdorf/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: sniffio in /Users/hannahmeyerzutittingdorf/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in /Users/hannahmeyerzutittingdorf/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.1.3-py3-none-any.whl (14 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/hannahmeyerzutittingdorf/opt/anaconda3/lib/python3.8/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, certifi, selenium\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.12.5\n",
      "    Uninstalling certifi-2020.12.5:\n",
      "      Successfully uninstalled certifi-2020.12.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.9.1 requires ruamel-yaml, which is not installed.\u001b[0m\n",
      "Successfully installed certifi-2023.7.22 exceptiongroup-1.1.3 h11-0.14.0 outcome-1.2.0 selenium-4.11.2 trio-0.22.2 trio-websocket-0.10.3 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484d354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stocks S&P 500 \n",
    "list_stocks = pd.read_excel(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/List S&P 500.xlsx\")\n",
    "list_stocks = list_stocks.iloc[:,0:6]\n",
    "\n",
    "# safe stock symbols as array\n",
    "stocks = list_stocks['Symbol'].to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1baa569",
   "metadata": {},
   "source": [
    "# Web Scrapping\n",
    "I download data with realized volatility of the S&P 500 stocks from the website https://dachxiu.chicagobooth.edu. The data is based on intraday data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cddb707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de44e61c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# open website\n",
    "driver = webdriver.Firefox()\n",
    "driver.get('https://dachxiu.chicagobooth.edu')\n",
    "\n",
    "for i in range(len(stocks)):\n",
    "    # search for stock\n",
    "    search_input = driver.find_element(By.ID, \"ticker\")\n",
    "    search_input.send_keys(stocks[i]+\" \")\n",
    "    suggestion = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//*[@class='symbol-one']\")))\n",
    "    driver.execute_script(\"arguments[0].click();\", suggestion)\n",
    "\n",
    "    # click download button\n",
    "    time.sleep(5)\n",
    "    download = driver.find_element(By.ID, \"data-download\")\n",
    "    driver.execute_script(\"arguments[0].click();\", download)\n",
    "\n",
    "    # click download in window\n",
    "    download_link = driver.find_element(By.ID, \"download-link\")\n",
    "    driver.execute_script(\"arguments[0].click();\", download_link)\n",
    "\n",
    "    # rename download document\n",
    "    new_name = \"/Users/hannahmeyerzutittingdorf/Downloads/\" + stocks[i] + \".csv\"\n",
    "    time.sleep(5)\n",
    "    os.rename(\"/Users/hannahmeyerzutittingdorf/Downloads/download.csv\", new_name)\n",
    "    #os.remove(\"/Users/hannahmeyerzutittingdorf/Downloads/download.csv\")\n",
    "\n",
    "    # reload website\n",
    "    driver.refresh()\n",
    "\n",
    "# close Browser when done\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ab2fa",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "38c1ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speciality with Google and Alphabet\n",
    "# GOOG 90319 is at Website Google INC\n",
    "# GOOG 14542 is Alphabet INC \n",
    "# rename GOOG 90139 to GOOGL\n",
    "googl = pd.read_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/GOOGL.csv\")\n",
    "googl['Symbol'] = 'GOOGL'\n",
    "googl.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/GOOGL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "44cfaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speciality with BRK.B and BF.B\n",
    "# named on website BRK/B and BF/B\n",
    "# problems with /\n",
    "# rename to BRKB and BFB\n",
    "brkb = pd.read_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/BRKB.csv\")\n",
    "brkb['Symbol'] = 'BRKB'\n",
    "brkb.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/BRKB.csv\")\n",
    "\n",
    "bfb = pd.read_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/BFB.csv\")\n",
    "bfb['Symbol'] = 'BFB'\n",
    "bfb.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/BFB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66091fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty dataframe\n",
    "data = pd.DataFrame({'Symbol' : [], 'PN' : [], 'Type' : [], 'Date' : [], 'Volatility' : []})\n",
    "\n",
    "path = \"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/Stockdata/\"\n",
    "\n",
    "#list for all missing stocks\n",
    "not_exist = []\n",
    "\n",
    "#loop over all stocks\n",
    "for i in range(len(stocks)):\n",
    "    stock_name = stocks[i]\n",
    "    file = Path(path + stock_name + \".csv\")\n",
    "    \n",
    "    # check if file exists\n",
    "    if file.is_file():\n",
    "        stock = pd.read_csv(path + stock_name + \".csv\")\n",
    "        \n",
    "        #without the data from the SPY ETF. which was as example on the website\n",
    "        data = pd.concat([data, stock[stock['Symbol'] != 'SPY']])\n",
    "    else:\n",
    "        not_exist.append(stock_name)\n",
    "        \n",
    "# delete Unnamed:0 column\n",
    "data.drop('Unnamed: 0', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "75d8253e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAL',\n",
       " 'ACE',\n",
       " 'AMB',\n",
       " 'CEG',\n",
       " 'EG',\n",
       " 'GEHC',\n",
       " 'JCI',\n",
       " 'KVUE',\n",
       " 'PARA',\n",
       " 'RVTY',\n",
       " 'STE',\n",
       " 'WBD',\n",
       " 'WELL',\n",
       " 'WLTW']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_exist\n",
    "\n",
    "# AAL American Airlines Group -> 2011 to 2014 is missing\n",
    "\n",
    "# CB Chubb Limited -> former ACE, data is missing between 2006 and 2016\n",
    "\n",
    "# CEG Constellation Energy -> splitted of from Exelon in 2022\n",
    "\n",
    "# EG Everest RE Group -> former Prudential Reinsurance as part of Prudential finance (already included)\n",
    "# cannot find EG\n",
    "\n",
    "# GEHC GE HeathCare -> was part of General Electric (already included) until January 2023 \n",
    "\n",
    "# KVUE -> Kenvue -> new company: 2022, former healthcare division of Johnson&Johnson\n",
    "# Johnson&Johnson is already included\n",
    "\n",
    "# JCI Johnson Controls -> data is missing between 2006 and 2017\n",
    "\n",
    "# PARA Paramount Global -> founded as ViacomCBS in 2019 \n",
    "# cannot find it, but not as important because relatively new company \n",
    "# -> will not be included because of short timeline\n",
    "\n",
    "# PLD Prologis -> AMB, but data missing between 2006 and 2011\n",
    "\n",
    "# RVTY Revvity -> founded May 2023\n",
    "\n",
    "# STE Steris -> 2015 to 2019 is missing\n",
    "\n",
    "# WBD Warner Bros Discovery -> founded April 2022\n",
    "\n",
    "# WELL Welltower -> former HCN but data is missing between 2006 and 2018\n",
    "\n",
    "# WLTW Willis Towers Watson -> data is missing between 2006 and 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ce55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete not existing stocks from the list of stocks\n",
    "stocks = [s for s in stocks if s not in not_exist]\n",
    "list_stocks = list_stocks[~list_stocks['Symbol'].isin(not_exist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "293075d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# delete column PN\n",
    "data.drop('PN', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "288d22f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add GICS Sector\n",
    "data = pd.merge(data, list_stocks[['Symbol', 'GICS Sector']], on = 'Symbol', how = 'outer')\n",
    "\n",
    "# check if a stock is missing\n",
    "missing = data[data['Type'].isna()]\n",
    "stocks_missing = np.array(missing['Symbol'])\n",
    "stocks_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "89a9ad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Date to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# split into trades and quotes\n",
    "data_trade = data[data['Type'] == 'QMLE-Trade']\n",
    "data_quote = data[data['Type'] == 'QMLE-Quote']\n",
    "\n",
    "# reset index\n",
    "data_trade = data_trade.reset_index()\n",
    "data_quote = data_quote.reset_index()\n",
    "\n",
    "data_trade.drop('index', inplace = True, axis = 1)\n",
    "data_quote.drop('index', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "02fba3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save as .csv\n",
    "data_trade.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/data_trade_original.csv\")\n",
    "data_quote.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/data_quote_original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857f0bc",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8f4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cutting time line from the right side\n",
    "def cutting_data_after(data, cutting_date):\n",
    "    '''\n",
    "    input: dataframe and cutting_date as string\n",
    "    output: cutted dataframe\n",
    "    cuts the timeline on the right side \n",
    "    \n",
    "    '''\n",
    "    # group by stock and sort each stock by date\n",
    "    grouped = data.groupby('Symbol')\n",
    "    sorted_grouped = grouped.apply(lambda x: x.sort_values('Date'))\n",
    "    \n",
    "    # Reset index\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # delete rows with Date larger or equal to cutting date\n",
    "    data = data[data['Date'] < cutting_date]\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e6e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for deleting complete stock which have a too short timeline \n",
    "# cut timeline of remaining stocks from the left\n",
    "def cutting_data_before(data, cutting_date):\n",
    "    '''\n",
    "    input: dataframe and cutting_date as string\n",
    "    output: cutted dataframe\n",
    "    cuts the timeline on the left side and deletes stocks with a too short timeline\n",
    "    '''\n",
    "    # group data by stock\n",
    "    grouped_stock = data.groupby('Symbol')\n",
    "    \n",
    "    # date where to cut timeline\n",
    "    date = datetime.strptime(cutting_date, '%Y-%m-%d')\n",
    "\n",
    "    # filter all groups which have a timeline at this date and not later\n",
    "    filtered_groups = grouped_stock.filter(lambda group: group.iloc[0]['Date'] <= date)\n",
    "    \n",
    "    # reset index\n",
    "    filtered_groups = filtered_groups.reset_index(drop = True)\n",
    "    \n",
    "    # delete rows with Date smaller than cutting date\n",
    "    filtered_groups = filtered_groups[filtered_groups['Date'] >= date]\n",
    "    \n",
    "    return filtered_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ee71f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_trade = pd.read_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/data_trade_original.csv\",\n",
    "                        index_col = 'Unnamed: 0')\n",
    "data_quote = pd.read_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/data_quote_original.csv\",\n",
    "                        index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36036172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Date to datetime format\n",
    "data_trade['Date'] = pd.to_datetime(data_trade['Date'])\n",
    "data_quote['Date'] = pd.to_datetime(data_quote['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0eeb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutting data on the right side\n",
    "data_trade = cutting_data_after(data_trade, '2023-08-01')\n",
    "data_quote = cutting_data_after(data_quote, '2023-08-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d447d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to find the optimal period length\n",
    "# filter the start of the timeline for each stock\n",
    "grouped_stock = data_trade.groupby('Symbol')\n",
    "start_timeline = grouped_stock.first()\n",
    "\n",
    "plt.hist(start_timeline['Date'], bins = 100)\n",
    "\n",
    "plt.show()\n",
    "# timelines for 317 stocks start in 1996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7deb87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cutting data on the left side and delete stocks with too short timeline\n",
    "# 2004-08-19 leads to 19 years\n",
    "data_trade = cutting_data_before(data_trade, '2014-08-08')\n",
    "data_quote = cutting_data_before(data_quote, '2014-08-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28fcf723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# number of trading days of S&P 500\n",
    "import yfinance as yf\n",
    "\n",
    "stock_symbol = \"AAPL\"\n",
    "\n",
    "# start and end dates\n",
    "start_date = \"2014-08-08\"\n",
    "end_date = \"2023-08-01\"\n",
    "\n",
    "# fecth historical data\n",
    "data_history = yf.download(stock_symbol, start = start_date, end=end_date)\n",
    "\n",
    "# Extract the trading days from the data\n",
    "trading_days = data_history.index.date.tolist()\n",
    "\n",
    "n_days = len(trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65393774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.0, 2259)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is easier for training the models if the number of days can be divided by 251\n",
    "n_days/251, n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a05b95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MM</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAP</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOXA</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRT</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>NKE</td>\n",
       "      <td>2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>AFL</td>\n",
       "      <td>2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>CPRT</td>\n",
       "      <td>2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>MCK</td>\n",
       "      <td>2246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>IFF</td>\n",
       "      <td>2253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  count\n",
       "0      MM    305\n",
       "1     TAP    326\n",
       "2    FOXA   1159\n",
       "3     FRT   2172\n",
       "4       J   2181\n",
       "..    ...    ...\n",
       "433   NKE   2245\n",
       "434   AFL   2245\n",
       "435  CPRT   2245\n",
       "436   MCK   2246\n",
       "437   IFF   2253\n",
       "\n",
       "[438 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some datapoints are missing\n",
    "# therefore difference in length of timeline betweeen stocks\n",
    "# fill the missing spots with mean\n",
    "\n",
    "counts = data_trade['Symbol'].value_counts().reset_index(name='count')\n",
    "counts = counts.sort_values(by ='count')\n",
    "counts = counts.reset_index(drop=True)\n",
    "counts\n",
    "\n",
    "# CME data points misisng but relative equally distributed -> around 1000 missing\n",
    "# all others around 4700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e54ea481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for filling the missing values with the mean of the days before and the days afterwards\n",
    "def filling_missing_values(df):\n",
    "    '''\n",
    "    input: dataframe with date, Symbol, Type, Volatility, GICS Sector\n",
    "    output: dataframe with date, Symbol, Type, Volatility, GICS Sector but with values for all trading days\n",
    "    -> timeline of every stock has same length\n",
    "    the missing values are filled with the mean of the days before and the days afterwards\n",
    "    '''\n",
    "    filled_df = pd.DataFrame(columns=['Date', 'Symbol', 'Type', 'Volatility','GICS Sector'])\n",
    "\n",
    "    for symbol, group in df.groupby('Symbol'):\n",
    "\n",
    "        #Need GICS Sector for filling missing values\n",
    "        gics = group.iloc[0, 4]\n",
    "\n",
    "        # delet duplicates (do not know why there are duplicates)\n",
    "        group.drop_duplicates(subset='Date', inplace=True)\n",
    "        # Reindex the group to include the full date range\n",
    "        group = group.set_index('Date').reindex(trading_days)\n",
    "\n",
    "        # Fill missing values with the mean of the days before and the days afterwards\n",
    "        volatility = pd.concat([group['Volatility'].fillna(method='ffill'),  \n",
    "                           group['Volatility'].fillna(method='bfill')], axis=1).mean(axis=1)\n",
    "        \n",
    "        group['Volatility'] = volatility\n",
    "\n",
    "        # Fill Symbol\n",
    "        group['Symbol'].fillna(symbol, inplace = True)\n",
    "\n",
    "        # Fill GICS Sector\n",
    "        group['GICS Sector'].fillna(gics, inplace = True)\n",
    "\n",
    "        # Reset the index and add the filled group to the new DataFrame\n",
    "        group = group.reset_index()\n",
    "        filled_df = pd.concat([filled_df, group], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Sort the filled DataFrame by 'Stock' and 'Date' if needed\n",
    "    filled_df.sort_values(by=['Symbol', 'Date'], inplace=True)\n",
    "\n",
    "    # If needed, reset the index\n",
    "    filled_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return filled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b27096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values in the dataframes\n",
    "data_trade = filling_missing_values(data_trade)\n",
    "data_trade['Type'] = 'QMLE-Trade'\n",
    "\n",
    "data_quote = filling_missing_values(data_quote)\n",
    "data_quote['Type'] = 'QMLE-Quote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13f73474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438.0, 438.0, 0, 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check \n",
    "# length of  df/trading days should be number of stocks\n",
    "# no NaNs should be left\n",
    "len(data_trade)/n_days, len(data_quote)/n_days, len(data_trade[data_trade['Volatility'].isna()]), len(data_quote[data_quote['Volatility'].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb419ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as .csv\n",
    "data_trade.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/data_trade.csv\")\n",
    "data_quote.to_csv(\"/Users/hannahmeyerzutittingdorf/Documents/Uni/Master/Masterarbeit/Daten/data_quote.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
